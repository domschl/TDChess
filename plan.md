## Current status, potential bugs, debug tools

Currently, the model tends to make suicide moves (pointless queen sacrifices) way too often.

There are a number of possible causes:

- simply not enough training
- horizont for quiescence search too limited
- problems introduced by multiple switches between minimax and negamax search strategies (bugs!)

The third cause can hide at different places:

- the signs of the initial training data generated by stockfish
- the signs of the gameplay data generated by the model
- the signs of the policy
- the search algorithm (both for 'Basic' eval and 'neural' eval)

In order to debug this, we need some visualization tools:

- snapshot of a few generated stockfish positions
- during game generation, the first few moves including evaluation should be displayed

## Performance

The model used is already quite minimal.


- In case of CUDA, we should use torch's compile options

## Review Findings (2026-02-14)

### 1. Training vs Inference Mismatch
There is a critical mismatch between training and inference:
- `pytorch_binding.cpp` applies `tanh()` to the model output.
- `train_neural.py` **does not** apply `tanh()` in the model's `forward` method or loss calculation (it uses `MSELoss` on the linear output).
- **Consequence**: The inference engine squashes the linear output output by the model, distorting larger evaluations. For example, a "+5.0" score from the model becomes `tanh(5.0) ~= 1.0` (max score), but a "+0.5" score becomes `0.46`. This nonlinearity likely causes the engine to misjudge the magnitude of advantages/disadvantages.

### 2. Dataset Size
The current dataset generation script defaults to 5,000 positions. This is extremely small for a chess neural network. "Suicide moves" are a classic symptom of underfitting or lack of coverage of tactical positions.

### 3. Evaluation Perspective
- Stockfish data is generated from **White's perspective**.
- The model trains on this.
- `pytorch_binding.cpp` flips the sign based on side-to-move.
- **Status**: This logic appears correct and consistent with `negamax`.

## Next Steps

### Phase 1: Fixes & Consistency
- [x] **Fix Tanh Mismatch**: Removed redundant tanh in C++ and unified scaling.
- [x] **Verify Normalization**: Aligned MAX_EVAL and centipawn scaling.
- [x] **Repetition Detection**: Added history tracking for draw-by-repetition.
- [x] **Search Speedups**: Implemented Null Move Pruning and Aspiration Windows.

### Phase 2: Debugging Tools
- [x] **Create `evaluate_fen.py`**: A Python script to load the model and evaluate a specific FEN.
- [ ] **Visualization**: Create a script to render the "suicide" positions to understand what the model "sees" (e.g. print the top-k highest activated planes).

### Phase 3: Scaling
- [x] **Generate Larger Dataset**: Implemented engine-assisted diversity and FEN deduplication.
- [x] **Deduplication**: Added data leakage protection in `ChessDataset`.
- [ ] **Retrain**: Retrain the model with the valid activation function and larger dataset.


